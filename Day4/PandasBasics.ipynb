{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "An Intro to PANDAS for the CDIPS Data Science pre-Workshop"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below is an intro to pandas.  The lines of code are formatted as raw text.  Like in Day 2, copy-paste the text into a new line to run (or just change the format of each cell to \"code\" through the menu above).  If you have any questions, feel free to email me, Joe: jthurakal + the usual Berkeley email extension (or raise your hand if you are in the classroom). If you have time, you may also want to check out the Kaggle tutorial on pandas: https://www.kaggle.com/c/titanic-gettingStarted/details/getting-started-with-python-ii"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First let's import some important libraries (and run a function that will be useful later on)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "import pandas as pd\n",
      "import numpy as np"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "def side_by_side(*objs, **kwds):\n",
      "    from pandas.core.common import adjoin\n",
      "    space = kwds.get('space', 4)\n",
      "    reprs = [repr(obj).split('\\n') for obj in objs]\n",
      "    print adjoin(space, *reprs)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Series\n",
      "======\n",
      "Series are like arrays.  The key difference being that indices aren't always ordered numbers. You can specify index values when making a Series object.  You can see this in the lines of code below.  In some very rare cases you have duplicate indices, but generally you want a unique set of indices (ie no duplicate index labels)."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "labels = ['a', 'b', 'c', 'd', 'e']\n",
      "s = pd.Series(np.random.randn(5), index=labels)\n",
      "s"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "'b' in s"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's refer to values on the Series through the index name."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "s['b']"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "s"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In spite of the new index labels in pandas, you also keep your favorite array indexing from numpy, as you can see below. Yay!!"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "s[:3]"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "s.index #here's a way to get the index names"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "s.values #and this returns the Series values in array format."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "DataFrame: 2D collection of Series\n",
      "=================================="
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A dataframe is a collection of Series that looks very similar to a table (like one you might see in Excel), but is way more useful, as we will see in this section.  Each column of the dataframe is a Series and the rows are referenced by the indices.  One can create a dataframe through a dict, as seen below.  Most of the time, you will be creating dataframes from files.  DataFrames are a powerful way to store and manipulate data.  This is what we will spending most of the session on."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "df = pd.DataFrame({'a': np.random.randn(6),\n",
      "                'b': ['foo', 'bar'] * 3,\n",
      "                'c': np.random.randn(6)})\n",
      "df"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "df.index"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With DataFrames, in addition to index, we have a new attribute call column. So <i> index </i> returns row names (labels) and <i>columns</i> returns a list of column headers.  "
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "df.columns "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Now let's try another type of index"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's arbitrary what values we use for the index.  Above, we've used numbers and letters.  Often, people have time series data (for example a table with the prices of various stocks on different days). The index in that case would be the date. See below on how to implement that.  Pandas is GREAT for dealing with time series (it was originally developed for that), but we won't even touch the subject right now."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "df = pd.DataFrame({'a': np.random.randn(6),\n",
      "                'b': ['foo', 'bar'] * 3,\n",
      "                'c': np.random.randn(6)},\n",
      "               index=pd.DateRange('1/1/2000', periods=6))\n",
      "df"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "What happens if you add a column, but don't provide any data for it?\n",
      "Test the line of code below to see what happens!"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "df = pd.DataFrame({'a': np.random.randn(6),\n",
      "                'b': ['foo', 'bar'] * 3,\n",
      "                'c': np.random.randn(6)},\n",
      "               columns=['a', 'b', 'c', 'd'])\n",
      "df"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You'll see a bunch of NaNs, which represent empty fields."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Let's take a look at some more interesting data...."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Imagine that you are a GSI (difficult, I know). You are interested in improving your student's performance (and also your teaching) so you design an evaluation form for your students to fill out.  You want it to be quick to fill out, so you go with questions where students give a rating from 1-5 (these can be scores or a reflection of how interested/disinterested they are on a scale of 1-5).\n",
      "\n",
      "As a quick warm-up (optional), let's come up with a couple of questions to put on an evaluation form. This is analgous to experimental design for a data scientist! To get some iPython practice- add a cell below this one and type your favorite questions in there (use the ipython menu to format it as either a markdown line or a raw text line).  I'll put the actual questions right below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are the actual questions"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Q1  I show up for discussion section\n",
      "Q2  I want to show up for discussion section\n",
      "Q3  I find discussion section useful\n",
      "Q4  Problems are too hard\n",
      "Q5  Problems are too easy\n",
      "Q6  Labs and feedback from lab are helpful to understand concepts\n",
      "Q7  Labs and feedback are good use of class time\n",
      "Q8  Quizzes and feedback are helpful to understand concepts\n",
      "Q9  GSI demonstrates command of subject matter\n",
      "Q10 GSI is fully prepared for class\n",
      "Q11 GSI provides clear and comprehensive explanations\n",
      "Q12 GSI asks thought-provoking questions\n",
      "Q13 GSI encourages student discussion\n",
      "Q14 GSI makes sure everyone understands the material\n",
      "Q15 GSI is accessible when I seek assistance\n",
      "Q16 GSI gives helpful written comments on assignments\n",
      "Q17 GSI seems genuinely concerned about my learning\n",
      "Q18 Overal GSI quality"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we are going to checkout some evaluation data! Let's load it in first using pandas."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals = pd.read_csv('GSIMidSemEvals.csv', ',') "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "See how easy this is?!  As an aside, the second parameter in the function is the delimiter in the file. A delimiter is the character that indicates when a new value is starting.  CSV stands for comma separated variables, so the delimiter here is naturally a comma character (',').  Pandas eliminates much of the headache in loading data files."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "type(evals) #notice instead of a bunch of strings as we got yesterday, we get a pandas object when we read this data.  This is a good thing :)."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.head(5) #because sometimes you just want to get a flavor of the data without the data getting all up in your grill"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b> Exercise: </b> Now add a line below this and to get the last 3 rows of the evals dataframe to display (the keyboard shortcut to add a cell below is ctrl+m+b.  To add one above is ctrl+m+a).  To do the exercise, you need a function similar to head (hint: in a coin flip, what's the opposite of heads?)  This is a googling exercise."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function application\n",
      "====================\n",
      "\n",
      "You can apply arbitrary functions to the rows or columns of a DataFrame.  This can be a great way to do initial exploration of your data.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Columns like Q1,Q2 ... are often referred to as <b><i>features</b></i>.  You will hear this term a lot."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.apply(np.mean) #notice what \"direction\" (rows vs columns) the function <apply> defaults across.  Why do you think this is? \n",
      "#Feel free to ask"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.dtypes #this is useful for checking the data types of each feature.  \n",
      "#Does Pandas agree with your opinion of the data types?  Any potential problems we can run into?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas is able to infer numerical types whenever it can detect them. So we have values already stored as integers. When it detected the existing decimal points in some columns, it converted those columns to float. Now try this to get more info about the DataFrame:\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.info() #Question: why are there discrepancies in the number of entries?  A data scientist might ask: Is this corrupted data?  A flaw in the collection? In finance, a quant might ask the equivalent- Did the data feed go down/was there a hardware failture?  Or was there just a bank holiday in that particular country?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that in PANDAS you can refer to each feature/column by name.  This is one of the ways pandas is more intuitive than numpy etc."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals[['StudentId', 'Sec']] = evals[['StudentId', 'Sec']].astype(str) \n",
      "#this is useful converting features to other data types if python has misinterpreted your csv file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Review </b>: Type in a command that will help you check if the above code worked.  You'll need to add a cell below this (practice those hot keys if you can):"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also use the following to map <i>Sec</i> into a binary value.  This is often done to categorical data as a preprocessing step for analysis.  For example, you could now run a regression on the Sec data with an interpretable meaning for the regression coefficient of the new variable. Sklearn.preprocessing has some great ways to do this too- you'll see some of this tomorrow. "
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals['Sec'].map( {'101': 0, '201': 1} ).astype(int)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Excercise</b>:  Convert some of the columns that are int to float below:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.ix[:,2:] #ix allows you to refer to the number location of each column OR the column name.  It is robust and therefore dope."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The line of code below doesn't work! How do we fix this?  You'll need to use something you just learned."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.apply(np.mean,axis=1) #how does this differ from our first apply np.mean example?  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Also, fix the same issue in the line of code below"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<i>side_by_side</i> is a pretty useful function that I found in a previous tutorial - puts two things side by side (the function is defined at the top of the sheet).  The line of code below puts the mean of each feature alongside its standard deviation:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "side_by_side(evals.apply(np.mean),evals.apply(np.std))"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can put in other fuctions into <i>apply</i>, and even build new dataframes from your current ones.  So pandas makes it easy to transform data in addition to aggregating it."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Iambda x is an built-in function of python for generating an anonymous function in the moment, at runtime.  Here's a cool way to use it to calculate the range of each feature"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.ix[:,2:].apply(lambda x: x.max() - x.min())"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also do operations on the dataframe to generate other, more intuitive values (I know, intuitive is in the eye of the beholder :)).  Below, I'm goign to transform the data.  This particular operation is especially useful when you are doing data analysis and want to normalize features that have a larger average or more variance.  After this transform, in a regression, the coefficient in front of each new feature tells you more about the explaining power of each variable instead of the scale of each value (ask me about this sentence, as I think I can explain it better in person with a little example).  Sklearn.preprocessing also has some good ways to do this."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "(evals.ix[:,2:] - np.mean(evals.ix[:,2:]))/np.std(evals.ix[:,2:])"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GroupBy\n",
      "======="
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "GroupBy is very useful for selecting and segmenting your data.  The next line of code will split the dataframe by section.  For fun, comment out print key or print group and see how the output changes"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "for key, group in evals.groupby('Sec'):\n",
      "    print key\n",
      "    print group"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next line of code will generate descriptive statistics on each section based on their answer to Question 10:  GSI is fully prepared for class.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data scientists, any theories on the difference?  I think there's one very good one."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.groupby('Sec')['Q10'].describe() #Question 10:  GSI is fully prepared for class.  \n",
      "#Any theories on the difference?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we will divide up the evals by Section (class) and study the response to Question 18 (our Q18 feature).  Notice I referred to the feature in another way.  This is one of the other advantages of pandas- very robust notation!"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.groupby('Sec').Q18.describe() #Question 18:  Overall GSI Quality. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also calculate statistics over these groups."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.groupby('Sec').mean()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Many of the early questions in the survey are also useful ways to segment the class.  However, what do you think these main problem is with using these questions as segments (look at the output below for a clue)- any way to alleviate this?"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "for key, group in evals.groupby('Q2'): #Question 2: I want to show up to discussion section (5 strongly agree,1 strongly disagree)\n",
      "    print key\n",
      "    print group"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also create new features in pandas very quickly to help you deal with emerging problems, or just for convenience sake.  Here, we'll tackle the oversegmentation of Q2 by splitting students into 2 groups:  Students who gave 4 or 5's and students who did not.  We'll call this new feature Q2P."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.ix[:,'Q2P'] = evals.ix[:,'Q2'] > 3.5"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As an aside, you can also create new features that are based on pre-existing features.  For example, you can create a product of two columns- this is useful to add second order terms to any linear regressions you may want to do. For example, let's create a new feature that's just the product of Q5 with Q6.  Notice I'm switching up my notation to show off how robust pandas is."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals['Q5Q6'] = evals.Q5*evals.Q6"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.Q5Q6.head() #remember we can go back and forth on notation.  I could have also typed evals['Q5Q6'].head()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's get back to Q2P now.  We can see there are no longer groups that are too small to analyze in the next line of code"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "for key, group in evals.groupby('Q2P'): #Question 2: I want to show up to discussion section (5 strongly agree,1 strongly disagree)\n",
      "    print key\n",
      "    print group"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below also does something similar, using a method you've probably seen before with numpy.  Give it a go."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals[evals['Q2']>3.5]"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals[evals['Q2']<=3.5]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's calculate averages segmented by this variable to see if there's a difference between the groups.  Q2 asks \"I want to show up for discussion section\", which might be a reflection of student attitudes towards the field, the classroom environment, or 8am class, so we might be able to get some insight into how this attitude might affect their evaluation of other aspects of the classroom and teaching  "
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.groupby(['Sec', 'Q2P']).mean()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next line does the same thing as above, but doesn't group the Q2P below the Section.  In contrast, the above does <u>heirarchical indexing </u>- not necessary to know what that is now, but wanted to introduce the idea- if only to see the difference in the output look."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.groupby(['Sec', 'Q2P'], as_index=False).mean()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Maybe Q2P isn't useful anymore.  You can drop as many features as you want from the dataframe using the following:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals = evals.drop(['Q2P'], axis=1)  #gets rid of all columns you don't want.  \n",
      "#You can put more column names into the list if you want to drop multiple columns"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals.head() #to test if what we did worked"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In many cases, having empty fields indicates a particular row contains bad data (though not in our case).  To drop all the rows that are missing values, use the following:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "evals = evals.dropna()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Time permitting, propose and test a descriptive insight you have into the evaluations.  We can share amongst ourselves at the end.  Use iPython to the fullest by documenting your thoughts and hypothesis as you go along."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}